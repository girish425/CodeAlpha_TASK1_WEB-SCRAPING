### Task 1 â€“ Web Scraping

----------------------------------------------





##### Introduction

----------------------

* Web scraping is a technique used to automatically extract data from websites.
* In this internship task, web scraping was performed using Python to collect relevant information from public web pages and convert it into structured datasets for analysis.
* This task helps in understanding real-world data collection and automation.



##### Objective

----------------

* To understand the structure of web pages (HTML)
* To extract relevant data from websites using Python
* To create custom datasets for analysis
* To clean and validate extracted data





##### Tools Used

------------------

* Python libraries-requests, beautifulsoup, pandas





##### Dataset created

-------------------------

* The dataset was created by scraping a website
* The dataset contains cleaned data, names of the books
* The cleaned dataset in stored in xlsx format for better analysis.



##### Stepwise process

-------------------------------

step-1 website selection

---

https://books.toscrape.com/



step-2 Understanding HTML Structure

---

identifying the html tags and books names within the structure



step-3 Fetching Web Page Content

---

the library used (requests) send http request and retrieves the content



step-4 Parsing HTML Content

----

The fetched HTML content was parsed using BeautifulSoup to navigate and locate required elements.



step-5 Data Extraction

---

Specific HTML tags were targeted to extract relevant data such as titles and prices.



step-6 Data Storage

---

the extracted data is stored in excel format making it user for analysis



step-7 data cleaning

---

the data is cleaned and checks for missing values and removes duplicates





##### **Conclusion**

**-----------------**



* This task provided hands-on experience in web scraping using Python. 
* I successfully extracted, cleaned, and stored web data into a structured format. The task enhanced my understanding of HTML, data collection techniques, and ethical scraping practices.
* &nbsp;Overall, this task helped me build a strong foundation in real-world data acquisition and preprocessing.



